{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3e21a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy \n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8186b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bearer token loaded with rate limiting\n"
     ]
    }
   ],
   "source": [
    "class X_tweets:\n",
    "    def __init__(self):\n",
    "        self.bearer_token = os.environ.get(\"TWITTER_BEARER_TOKEN\")\n",
    "        if not self.bearer_token:\n",
    "            print(\"‚ùå Please add your Bearer Token to the .env file\")\n",
    "            return\n",
    "        \n",
    "        self.client = tweepy.Client(bearer_token=self.bearer_token)\n",
    "        self.last_request_time = 0\n",
    "        self.min_delay = 5  # 5 seconds between requests\n",
    "        print(\"‚úÖ Bearer token loaded with rate limiting\")\n",
    "\n",
    "    def _rate_limited_request(self):\n",
    "        \"\"\"Ensure minimum delay between requests\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        if time_since_last < self.min_delay:\n",
    "            sleep_time = self.min_delay - time_since_last\n",
    "            time.sleep(sleep_time)\n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "    def get_user_info(self, username):\n",
    "        \"\"\"get basic details of the user\"\"\"\n",
    "        self._rate_limited_request()\n",
    "        \n",
    "        try:\n",
    "            user = self.client.get_user(\n",
    "                username=username,\n",
    "                user_fields=[\"public_metrics\", \"description\", \"created_at\"]\n",
    "            )\n",
    "            return user.data\n",
    "        except tweepy.TooManyRequests:\n",
    "            print(\"‚è∞ Rate limit hit! Waiting 15 minutes...\")\n",
    "            time.sleep(900)  # Wait 15 minutes\n",
    "            return self.get_user_info(username)  # Retry\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching user info: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_users_tweets(self, username, max_tweets=10):\n",
    "        \"\"\"fetch tweets from username\"\"\"  # ‚úÖ Fixed: now takes username\n",
    "        self._rate_limited_request()\n",
    "        \n",
    "        try:\n",
    "            # First get user to get ID\n",
    "            user = self.client.get_user(username=username)\n",
    "            time.sleep(3)  # Extra wait before tweets\n",
    "            \n",
    "            tweets = self.client.get_users_tweets(\n",
    "                user.data.id,  # ‚úÖ Fixed: use user.data.id\n",
    "                max_results=max_tweets,\n",
    "                tweet_fields=[\"created_at\", \"text\", \"public_metrics\", \"context_annotations\"],\n",
    "                exclude=[\"retweets\", \"replies\"]\n",
    "            )\n",
    "            return tweets.data if tweets.data else []\n",
    "        except tweepy.TooManyRequests:\n",
    "            print(\"‚è∞ Rate limit hit on tweets! Waiting 15 minutes...\")\n",
    "            time.sleep(900)\n",
    "            return self.get_users_tweets(username, max_tweets)  # Retry\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching tweets: {e}\")\n",
    "            return []\n",
    "\n",
    "Tweets = X_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59ade4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced analytics functions ready!\n"
     ]
    }
   ],
   "source": [
    "class X_profile_analytics:\n",
    "    def __init__(self, tweets):\n",
    "        self.tweets = tweets\n",
    "        self.df = self.tweets_to_dataframe()\n",
    "        self.username = \"\"  # Will be set from calling function\n",
    "        \n",
    "    def tweets_to_dataframe(self):\n",
    "        \"\"\"Convert tweets to comprehensive DataFrame\"\"\"\n",
    "        data = []\n",
    "        for tweet in self.tweets:\n",
    "            # Calculate engagement score\n",
    "            engagement = (tweet.public_metrics['like_count'] + \n",
    "                         tweet.public_metrics['retweet_count'] + \n",
    "                         tweet.public_metrics['reply_count'] + \n",
    "                         tweet.public_metrics['quote_count'])\n",
    "            \n",
    "            # Extract tweet features\n",
    "            text = tweet.text\n",
    "            word_count = len(text.split())\n",
    "            has_hashtags = '#' in text\n",
    "            has_mentions = '@' in text\n",
    "            has_links = 'http' in text or 'https' in text\n",
    "            is_thread = text.startswith('1/') or '1/' in text[:10]\n",
    "            \n",
    "            # Posting time analysis\n",
    "            created_at = tweet.created_at\n",
    "            hour = created_at.hour\n",
    "            day_of_week = created_at.strftime('%A')\n",
    "            \n",
    "            data.append({\n",
    "                'text': text,\n",
    "                'created_at': created_at,\n",
    "                'hour': hour,\n",
    "                'day_of_week': day_of_week,\n",
    "                'likes': tweet.public_metrics['like_count'],\n",
    "                'retweets': tweet.public_metrics['retweet_count'],\n",
    "                'replies': tweet.public_metrics['reply_count'],\n",
    "                'quotes': tweet.public_metrics['quote_count'],\n",
    "                'engagement': engagement,\n",
    "                'word_count': word_count,\n",
    "                'has_hashtags': has_hashtags,\n",
    "                'has_mentions': has_mentions,\n",
    "                'has_links': has_links,\n",
    "                'is_thread': is_thread,\n",
    "                'engagement_rate': engagement / max(tweet.public_metrics['like_count'], 1)\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        return df\n",
    "\n",
    "    def get_top_tweets_detailed(self, n=3):\n",
    "        \"\"\"Get detailed top tweets with full analysis\"\"\"\n",
    "        top_tweets = self.df.nlargest(n, 'engagement')\n",
    "        \n",
    "        print(\"üî• TOP PERFORMING TWEETS (Detailed Analysis)\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for idx, (_, tweet) in enumerate(top_tweets.iterrows(), 1):\n",
    "            print(f\"\\n{idx}. üìà ENGAGEMENT: {tweet['engagement']:,}\")\n",
    "            print(f\"   üëç Likes: {tweet['likes']:,} | üîÑ RT: {tweet['retweets']:,} | üí¨ Replies: {tweet['replies']:,}\")\n",
    "            print(f\"   üïê Posted: {tweet['created_at'].strftime('%Y-%m-%d %H:%M')}\")\n",
    "            print(f\"   üìù Words: {tweet['word_count']} | Thread: {'Yes' if tweet['is_thread'] else 'No'}\")\n",
    "            \n",
    "            # Show tweet text (truncated if too long)\n",
    "            text = tweet['text']\n",
    "            if len(text) > 200:\n",
    "                print(f\"   üí≠ \\\"{text[:200]}...\\\"\")\n",
    "            else:\n",
    "                print(f\"   üí≠ \\\"{text}\\\"\")\n",
    "            \n",
    "            # Performance insights\n",
    "            if tweet['engagement'] > self.df['engagement'].mean() * 2:\n",
    "                print(\"   ‚≠ê OUTSTANDING performance!\")\n",
    "            elif tweet['engagement'] > self.df['engagement'].mean():\n",
    "                print(\"   ‚úÖ Above average performance\")\n",
    "        \n",
    "        return top_tweets\n",
    "\n",
    "    def analyze_posting_patterns(self):\n",
    "        \"\"\"Analyze when tweets perform best\"\"\"\n",
    "        print(\"\\n‚è∞ POSTING PATTERN ANALYSIS\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Best hours\n",
    "        hourly_engagement = self.df.groupby('hour')['engagement'].mean()\n",
    "        best_hour = hourly_engagement.idxmax()\n",
    "        best_hour_engagement = hourly_engagement.max()\n",
    "        \n",
    "        print(f\"üïê Best posting hour: {best_hour}:00 ({best_hour_engagement:.1f} avg engagement)\")\n",
    "        \n",
    "        # Best days\n",
    "        daily_engagement = self.df.groupby('day_of_week')['engagement'].mean()\n",
    "        best_day = daily_engagement.idxmax()\n",
    "        best_day_engagement = daily_engagement.max()\n",
    "        \n",
    "        print(f\"üìÖ Best posting day: {best_day} ({best_day_engagement:.1f} avg engagement)\")\n",
    "        \n",
    "        # Content type analysis\n",
    "        thread_engagement = self.df[self.df['is_thread']]['engagement'].mean()\n",
    "        single_engagement = self.df[~self.df['is_thread']]['engagement'].mean()\n",
    "        \n",
    "        print(\"üßµ Content Performance:\")\n",
    "        print(f\"   Thread tweets: {thread_engagement:.1f} avg engagement\")\n",
    "        print(f\"   Single tweets: {single_engagement:.1f} avg engagement\")\n",
    "        \n",
    "        if thread_engagement > single_engagement:\n",
    "            print(\"   üí° Threads perform better than single tweets\")\n",
    "        else:\n",
    "            print(\"   üí° Single tweets perform better than threads\")\n",
    "        \n",
    "        return {\n",
    "            'best_hour': best_hour,\n",
    "            'best_day': best_day,\n",
    "            'thread_advantage': thread_engagement > single_engagement\n",
    "        }\n",
    "\n",
    "    def analyze_content_types(self):\n",
    "        \"\"\"Analyze what types of content perform best\"\"\"\n",
    "        print(\"\\nüìä CONTENT TYPE ANALYSIS\")\n",
    "        print(\"-\" * 25)\n",
    "        \n",
    "        # Hashtag analysis\n",
    "        hashtag_tweets = self.df[self.df['has_hashtags']]\n",
    "        no_hashtag_tweets = self.df[~self.df['has_hashtags']]\n",
    "        \n",
    "        hashtag_avg = hashtag_tweets['engagement'].mean() if len(hashtag_tweets) > 0 else 0\n",
    "        no_hashtag_avg = no_hashtag_tweets['engagement'].mean() if len(no_hashtag_tweets) > 0 else 0\n",
    "        \n",
    "        print(\"üè∑Ô∏è Hashtag Performance:\")\n",
    "        print(f\"   With hashtags: {hashtag_avg:.1f} avg engagement\")\n",
    "        print(f\"   Without hashtags: {no_hashtag_avg:.1f} avg engagement\")\n",
    "        \n",
    "        if hashtag_avg > no_hashtag_avg:\n",
    "            print(\"   üí° Tweets with hashtags perform better\")\n",
    "        else:\n",
    "            print(\"   üí° Tweets without hashtags perform better\")\n",
    "        \n",
    "        # Link analysis\n",
    "        link_tweets = self.df[self.df['has_links']]\n",
    "        no_link_tweets = self.df[~self.df['has_links']]\n",
    "        \n",
    "        link_avg = link_tweets['engagement'].mean() if len(link_tweets) > 0 else 0\n",
    "        no_link_avg = no_link_tweets['engagement'].mean() if len(no_link_tweets) > 0 else 0\n",
    "        \n",
    "        print(\"üîó Link Performance:\")\n",
    "        print(f\"   With links: {link_avg:.1f} avg engagement\")\n",
    "        print(f\"   Without links: {no_link_avg:.1f} avg engagement\")\n",
    "        \n",
    "        if link_avg > no_link_avg:\n",
    "            print(\"   üí° Tweets with links perform better\")\n",
    "        else:\n",
    "            print(\"   üí° Tweets without links perform better\")\n",
    "        \n",
    "        return {\n",
    "            'hashtag_advantage': hashtag_avg > no_hashtag_avg,\n",
    "            'link_advantage': link_avg > no_link_avg\n",
    "        }\n",
    "\n",
    "    def extract_hook_lines_advanced(self):\n",
    "        \"\"\"Advanced hook line analysis\"\"\"\n",
    "        print(\"\\nüé£ HOOK LINE ANALYSIS\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        # Get first sentences/phrases\n",
    "        hooks = []\n",
    "        for text in self.df['text']:\n",
    "            # Get first sentence or first 50 chars\n",
    "            if '.' in text[:100]:\n",
    "                hook = text.split('.')[0] + '.'\n",
    "            else:\n",
    "                hook = text[:50] + '...'\n",
    "            hooks.append(hook)\n",
    "        \n",
    "        hook_counts = Counter(hooks)\n",
    "        top_hooks = hook_counts.most_common(5)\n",
    "        \n",
    "        print(\"Most used opening lines:\")\n",
    "        for i, (hook, count) in enumerate(top_hooks, 1):\n",
    "            if count > 1:  # Only show repeated hooks\n",
    "                print(f\"{i}. \\\"{hook}\\\" (used {count}x)\")\n",
    "        \n",
    "        return top_hooks\n",
    "\n",
    "    def analyze_topics_advanced(self):\n",
    "        \"\"\"Advanced topic analysis with better keyword extraction\"\"\"\n",
    "        print(\"\\nüè∑Ô∏è ADVANCED TOPIC ANALYSIS\")\n",
    "        print(\"-\" * 25)\n",
    "        \n",
    "        all_text = ' '.join(self.df['text'])\n",
    "        \n",
    "        # Better word extraction (remove very common words)\n",
    "        words = re.findall(r'\\b\\w{4,}\\b', all_text.lower())\n",
    "        \n",
    "        # Expanded stop words\n",
    "        stop_words = {\n",
    "            'this', 'that', 'with', 'have', 'will', 'from', 'they', 'been', 'said', 'each', 'which', 'their',\n",
    "            'time', 'will', 'about', 'would', 'there', 'could', 'other', 'what', 'when', 'where', 'here',\n",
    "            'come', 'came', 'some', 'them', 'then', 'than', 'were', 'like', 'just', 'know', 'take', 'into',\n",
    "            'year', 'your', 'good', 'want', 'give', 'most', 'these', 'also', 'well', 'only', 'very', 'even',\n",
    "            'back', 'make', 'much', 'work', 'life', 'people', 'think', 'going', 'still', 'after', 'first'\n",
    "        }\n",
    "        \n",
    "        # Filter words\n",
    "        meaningful_words = [word for word in words if word not in stop_words and len(word) > 3]\n",
    "        \n",
    "        # Get hashtags\n",
    "        hashtags = re.findall(r'#\\w+', all_text.lower())\n",
    "        \n",
    "        # Show results\n",
    "        keywords = Counter(meaningful_words).most_common(10)\n",
    "        hashtag_counts = Counter(hashtags).most_common(10)\n",
    "        \n",
    "        if keywords:\n",
    "            print(\"Top Keywords:\")\n",
    "            for keyword, count in keywords[:8]:\n",
    "                print(f\"  {keyword}: {count}\")\n",
    "        \n",
    "        if hashtag_counts:\n",
    "            print(\"\\nTop Hashtags:\")\n",
    "            for hashtag, count in hashtag_counts[:5]:\n",
    "                print(f\"  {hashtag}: {count}\")\n",
    "        \n",
    "        return {\n",
    "            'keywords': keywords,\n",
    "            'hashtags': hashtag_counts\n",
    "        }\n",
    "\n",
    "    def generate_recommendations(self):\n",
    "        \"\"\"Generate actionable recommendations\"\"\"\n",
    "        print(\"\\nüí° ACTIONABLE RECOMMENDATIONS\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Analyze patterns\n",
    "        patterns = self.analyze_posting_patterns()\n",
    "        content = self.analyze_content_types()\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Posting time recommendations\n",
    "        if patterns['best_hour'] < 12:\n",
    "            recommendations.append(f\"üìÖ Post more during morning hours (around {patterns['best_hour']}:00)\")\n",
    "        else:\n",
    "            recommendations.append(f\"üìÖ Post more during evening hours (around {patterns['best_hour']}:00)\")\n",
    "        \n",
    "        recommendations.append(f\"üìä Focus on posting on {patterns['best_day']}s\")\n",
    "        \n",
    "        # Content recommendations\n",
    "        if patterns['thread_advantage']:\n",
    "            recommendations.append(\"üßµ Create more threads - they perform better\")\n",
    "        else:\n",
    "            recommendations.append(\"üìù Focus on single impactful tweets\")\n",
    "        \n",
    "        if content['hashtag_advantage']:\n",
    "            recommendations.append(\"üè∑Ô∏è Use relevant hashtags in your tweets\")\n",
    "        else:\n",
    "            recommendations.append(\"üö´ Avoid unnecessary hashtags\")\n",
    "        \n",
    "        if content['link_advantage']:\n",
    "            recommendations.append(\"üîó Include links when sharing resources\")\n",
    "        \n",
    "        # Engagement recommendations\n",
    "        avg_engagement = self.df['engagement'].mean()\n",
    "        if avg_engagement < 100:\n",
    "            recommendations.append(\"üìà Work on increasing overall engagement\")\n",
    "        elif avg_engagement > 1000:\n",
    "            recommendations.append(\"üöÄ Your content strategy is working well!\")\n",
    "        \n",
    "        # Display recommendations\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "    def engagement_stats(self):\n",
    "        \"\"\"Enhanced engagement statistics\"\"\"\n",
    "        if len(self.df) == 0:\n",
    "            return {'error': 'No tweets to analyze'}\n",
    "        \n",
    "        # Calculate percentiles\n",
    "        engagement_75th = self.df['engagement'].quantile(0.75)\n",
    "        engagement_median = self.df['engagement'].median()\n",
    "        \n",
    "        stats = {\n",
    "            'total_tweets': len(self.df),\n",
    "            'avg_likes': round(self.df['likes'].mean(), 1),\n",
    "            'avg_retweets': round(self.df['retweets'].mean(), 1),\n",
    "            'avg_replies': round(self.df['replies'].mean(), 1),\n",
    "            'avg_engagement': round(self.df['engagement'].mean(), 1),\n",
    "            'median_engagement': round(engagement_median, 1),\n",
    "            'top_25_percentile': round(engagement_75th, 1),\n",
    "            'best_performing': self.df['engagement'].max(),\n",
    "            'engagement_rate': f\"{round(self.df['engagement'].sum() / len(self.df), 1)} per tweet\",\n",
    "            'consistency_score': round(self.df['engagement'].std() / self.df['engagement'].mean(), 2)\n",
    "        }\n",
    "        \n",
    "        # Add interpretation\n",
    "        if stats['consistency_score'] < 0.5:\n",
    "            stats['consistency_note'] = \"Very consistent engagement\"\n",
    "        elif stats['consistency_score'] < 1.0:\n",
    "            stats['consistency_note'] = \"Moderately consistent engagement\"\n",
    "        else:\n",
    "            stats['consistency_note'] = \"Highly variable engagement\"\n",
    "        \n",
    "        return stats\n",
    "\n",
    "print(\"‚úÖ Enhanced analytics functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a1b08b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ COMPREHENSIVE TWITTER PROFILE ANALYSIS\n",
      "============================================================\n",
      "üìä Analyzing: @im_roy_lee\n",
      "============================================================\n",
      "üë§ Roy (@im_roy_lee)\n",
      "üìà Followers: 152,357\n",
      "üìù Bio: CEO at Cluely (@cluely) | Kicked out of Columbia and Harvard | i am the man who killed leetcode | @zfellows...\n",
      "\n",
      "‚è≥ Preparing tweet analysis...\n",
      "üì• Fetching recent tweets...\n",
      "‚úÖ Successfully fetched 20 tweets for analysis\n",
      "____________________________________________________________\n",
      "üìà ENGAGEMENT OVERVIEW\n",
      "-------------------------\n",
      "Total Tweets: 20\n",
      "Avg Likes: 1971.2\n",
      "Avg Retweets: 54.3\n",
      "Avg Replies: 108.9\n",
      "Avg Engagement: 2159.3\n",
      "Median Engagement: 490.0\n",
      "Top 25 Percentile: 1577.2\n",
      "Best Performing: 20553\n",
      "Engagement Rate: 2159.3 per tweet\n",
      "Consistency Score: 2.15\n",
      "Consistency: Highly variable engagement\n",
      "\n",
      "üî• TOP PERFORMING TWEETS (Detailed Analysis)\n",
      "==================================================\n",
      "\n",
      "1. üìà ENGAGEMENT: 20,553\n",
      "   üëç Likes: 19,532 | üîÑ RT: 602 | üí¨ Replies: 361\n",
      "   üïê Posted: 2025-08-09 19:48\n",
      "   üìù Words: 7 | Thread: No\n",
      "   üí≠ \"we r live in times square https://t.co/YcdFYaucGe\"\n",
      "   ‚≠ê OUTSTANDING performance!\n",
      "\n",
      "2. üìà ENGAGEMENT: 7,193\n",
      "   üëç Likes: 6,511 | üîÑ RT: 223 | üí¨ Replies: 343\n",
      "   üïê Posted: 2025-08-10 22:24\n",
      "   üìù Words: 51 | Thread: No\n",
      "   üí≠ \"message to all ~7,000 people on tech twitter:\n",
      "\n",
      "THIS IS A TINY BUBBLE\n",
      "\n",
      "NORMIES DON'T KNOW WHAT CLAUDE IS AND HALF HAVE NOT TRIED CHATGPT\n",
      "\n",
      "TRY TO GET BILLIONS OF VIEWS, NOT MILLIONS\n",
      "\n",
      "SINCE 2022; CULTURE...\"\n",
      "   ‚≠ê OUTSTANDING performance!\n",
      "\n",
      "3. üìà ENGAGEMENT: 3,813\n",
      "   üëç Likes: 3,257 | üîÑ RT: 68 | üí¨ Replies: 357\n",
      "   üïê Posted: 2025-08-27 04:02\n",
      "   üìù Words: 13 | Thread: No\n",
      "   üí≠ \"Course live now.\n",
      "\n",
      "$4999 for the next 24 hours\n",
      "\n",
      "cluely . university https://t.co/OJrKcxRDNy\"\n",
      "   ‚úÖ Above average performance\n",
      "\n",
      "‚è∞ POSTING PATTERN ANALYSIS\n",
      "------------------------------\n",
      "üïê Best posting hour: 19:00 (4960.6 avg engagement)\n",
      "üìÖ Best posting day: Saturday (10840.0 avg engagement)\n",
      "üßµ Content Performance:\n",
      "   Thread tweets: nan avg engagement\n",
      "   Single tweets: 2159.3 avg engagement\n",
      "   üí° Single tweets perform better than threads\n",
      "\n",
      "üìä CONTENT TYPE ANALYSIS\n",
      "-------------------------\n",
      "üè∑Ô∏è Hashtag Performance:\n",
      "   With hashtags: 0.0 avg engagement\n",
      "   Without hashtags: 2159.3 avg engagement\n",
      "   üí° Tweets without hashtags perform better\n",
      "üîó Link Performance:\n",
      "   With links: 1982.0 avg engagement\n",
      "   Without links: 3755.0 avg engagement\n",
      "   üí° Tweets without links perform better\n",
      "\n",
      "üé£ HOOK LINE ANALYSIS\n",
      "--------------------\n",
      "Most used opening lines:\n",
      "\n",
      "üè∑Ô∏è ADVANCED TOPIC ANALYSIS\n",
      "-------------------------\n",
      "Top Keywords:\n",
      "  https: 18\n",
      "  cluely: 5\n",
      "  views: 4\n",
      "  short: 3\n",
      "  form: 3\n",
      "  every: 2\n",
      "  meeting: 2\n",
      "  interns: 2\n",
      "\n",
      "üí° ACTIONABLE RECOMMENDATIONS\n",
      "------------------------------\n",
      "\n",
      "‚è∞ POSTING PATTERN ANALYSIS\n",
      "------------------------------\n",
      "üïê Best posting hour: 19:00 (4960.6 avg engagement)\n",
      "üìÖ Best posting day: Saturday (10840.0 avg engagement)\n",
      "üßµ Content Performance:\n",
      "   Thread tweets: nan avg engagement\n",
      "   Single tweets: 2159.3 avg engagement\n",
      "   üí° Single tweets perform better than threads\n",
      "\n",
      "üìä CONTENT TYPE ANALYSIS\n",
      "-------------------------\n",
      "üè∑Ô∏è Hashtag Performance:\n",
      "   With hashtags: 0.0 avg engagement\n",
      "   Without hashtags: 2159.3 avg engagement\n",
      "   üí° Tweets without hashtags perform better\n",
      "üîó Link Performance:\n",
      "   With links: 1982.0 avg engagement\n",
      "   Without links: 3755.0 avg engagement\n",
      "   üí° Tweets without links perform better\n",
      "1. üìÖ Post more during evening hours (around 19:00)\n",
      "2. üìä Focus on posting on Saturdays\n",
      "3. üìù Focus on single impactful tweets\n",
      "4. üö´ Avoid unnecessary hashtags\n",
      "5. üöÄ Your content strategy is working well!\n",
      "\n",
      "üéâ Analysis complete for @im_roy_lee!\n",
      "Use these insights to optimize your Twitter strategy! üöÄ\n"
     ]
    }
   ],
   "source": [
    "username = \"im_roy_lee\"\n",
    "\n",
    "print(\"üöÄ COMPREHENSIVE TWITTER PROFILE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Analyzing: @{username}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Get user info\n",
    "user_info = Tweets.get_user_info(username)\n",
    "\n",
    "if user_info:\n",
    "    print(f\"üë§ {user_info.name} (@{user_info.username})\")\n",
    "    print(f\"üìà Followers: {user_info.public_metrics['followers_count']:,}\")\n",
    "    print(f\"üìù Bio: {user_info.description[:120]}...\")\n",
    "    print()\n",
    "    \n",
    "    # Step 2: Wait before tweets\n",
    "    print(\"‚è≥ Preparing tweet analysis...\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Step 3: Get tweets\n",
    "    print(\"üì• Fetching recent tweets...\")\n",
    "    tweets = Tweets.get_users_tweets(username, max_tweets=20)\n",
    "    \n",
    "    if tweets:\n",
    "        print(f\"‚úÖ Successfully fetched {len(tweets)} tweets for analysis\")\n",
    "        print(\"_\" * 60)\n",
    "        \n",
    "        # Step 4: Initialize enhanced analyzer\n",
    "        tweet_analyzer = X_profile_analytics(tweets)\n",
    "        tweet_analyzer.username = username\n",
    "        \n",
    "        # Step 5: Comprehensive Analysis\n",
    "        \n",
    "        # 1. Engagement Statistics\n",
    "        print(\"üìà ENGAGEMENT OVERVIEW\")\n",
    "        print(\"-\" * 25)\n",
    "        stats = tweet_analyzer.engagement_stats()\n",
    "        for key, value in stats.items():\n",
    "            if key != 'consistency_note' and 'error' not in key:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "        if 'consistency_note' in stats:\n",
    "            print(f\"Consistency: {stats['consistency_note']}\")\n",
    "        print()\n",
    "        \n",
    "        # 2. Top Tweets Analysis\n",
    "        tweet_analyzer.get_top_tweets_detailed(3)\n",
    "        \n",
    "        # 3. Posting Patterns\n",
    "        patterns = tweet_analyzer.analyze_posting_patterns()\n",
    "        \n",
    "        # 4. Content Analysis\n",
    "        content = tweet_analyzer.analyze_content_types()\n",
    "        \n",
    "        # 5. Hook Analysis\n",
    "        tweet_analyzer.extract_hook_lines_advanced()\n",
    "        \n",
    "        # 6. Topic Analysis\n",
    "        tweet_analyzer.analyze_topics_advanced()\n",
    "        \n",
    "        # 7. Recommendations\n",
    "        tweet_analyzer.generate_recommendations()\n",
    "        \n",
    "        print(f\"\\nüéâ Analysis complete for @{username}!\")\n",
    "        print(\"Use these insights to optimize your Twitter strategy! üöÄ\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Could not fetch tweets\")\n",
    "        print(\"üí° This might be due to rate limiting. Wait 15 minutes and try again.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Could not get user information\")\n",
    "    print(\"üí° Check your Bearer Token or try a different username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9079fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
